{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1705045a-3513-4a35-969c-70933d0ffb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Any, Dict, List, Union\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import SystemMessage, HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b67203-063b-43e4-842b-8780a3baf2e4",
   "metadata": {},
   "source": [
    "## EXAMPLE CALLS USING NATIVE WEBSEARCH TOOLS FOR OPENAI AND ANTHROPIC\n",
    "1. OpenAI form\n",
    "2. OpenAI application with JSON\n",
    "3. Anthropic form\n",
    "4. Anthropic application with JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba7fde-43ec-43e9-8d7f-d3353f7aef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1. OPEN AI WEBSEARCH CALL\n",
    "gpt5 = ChatOpenAI(model=\"gpt-5\",\n",
    "                  use_responses_api=True,    \n",
    "                  reasoning={\"effort\": \"low\"},    \n",
    "                  model_kwargs={\n",
    "                      \"tools\": [{\"type\": \"web_search_preview\"}],\n",
    "                      \"text\":{\"verbosity\": \"low\"},   \n",
    "                      \"max_output_tokens\":1024, \n",
    "                      },\n",
    "                  )\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a news summarizer.\"),\n",
    "    HumanMessage(content=\"Summarize the most recent article you can find on OpenAI news.\")\n",
    "]\n",
    "\n",
    "oai_response = gpt5.invoke(messages)\n",
    "\n",
    "print(oai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c48150-7f12-4079-b04a-f9778100ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2. OPEN AI WEBSEARCH WITH JSON SCHEMA\n",
    "# Structured Responses will not work with websearch so you have to request a JSON response which for 4o and above is 90%+ accurate.\n",
    "# alternative is Langgraph/langchain AI workflow and break it into multiple calls.\n",
    "\n",
    "\n",
    "gpt4o = ChatOpenAI(model=\"gpt-4o\",  # or gpt-4.1\n",
    "                   temperature=0,  #task dependent but for computational/JSON stuff stereotypy good\n",
    "                   max_tokens=1024,\n",
    "                   model_kwargs={\n",
    "                   \"tools\": [{\"type\": \"web_search_preview\"}],\n",
    "                   \"tool_choice\": \"auto\",\n",
    "                       },\n",
    "                   )\n",
    "\n",
    "#A JSON Schema is a formatted JSON definition.\n",
    "schema = \"\"\"\n",
    "{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"summary\": { \"type\": \"string\" },\n",
    "    \"sources\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } }\n",
    "  },\n",
    "  \"required\": [\"summary\", \"sources\"],\n",
    "  \"additionalProperties\": false\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "system_message = f\" You are a news summarizer. Return a JSON object that strictly follows this JSON schema: {schema}\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=\"Summarize the most recent article you can find on OpenAI news.\")\n",
    "]\n",
    "\n",
    "oai_response = gpt4o.invoke(messages)\n",
    "\n",
    "print(oai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe61294-853b-4941-b2b0-9ef90c0193de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3. ANTHROPIC WEBSEARCH CALL\n",
    "# Anthropic web search seems to be less functional-- it seems to directly return tool results with commentary. \n",
    "# Documentation says the encrypted strings help Claude track references.\n",
    "\n",
    "claude = ChatAnthropic(model=\"claude-opus-4-1-20250805\", #\"claude-sonnet-4-20250514\", #\"claude-3-7-sonnet-20250219\",  # or \"\"claude-opus-4-1-20250805\", etc.\n",
    "                       temperature=0,\n",
    "                       max_tokens=1024,\n",
    "                       # Pass the server tool directly; no client implementation needed\n",
    "                       model_kwargs={\n",
    "                           \"tools\": [{\n",
    "                               \"type\": \"web_search_20250305\",\n",
    "                               \"name\": \"web_search\",\n",
    "                               \"max_uses\": 3,\n",
    "                               }]\n",
    "                           },\n",
    "                       )\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a news summarizer.\"),\n",
    "    HumanMessage(content=\"Find the most recent  news article you can addressing news from OpenAI.\")\n",
    "]\n",
    "\n",
    "#Claude seems not to integrate across search results so the first call needs to be content for a second?\n",
    "claude_response1 = claude.invoke(messages)\n",
    "messages.append(claude_response1)\n",
    "\n",
    "messages.append(HumanMessage(content=\"Summarize the most recent article on OpenAI news that was returned from your previous web search.\"))\n",
    "claude = ChatAnthropic(model=\"claude-sonnet-4-20250514\", #\"claude-3-7-sonnet-20250219\",  # or \"\"claude-opus-4-1-20250805\", etc.\n",
    "                       temperature=0.5,\n",
    "                       max_tokens=1024\n",
    "                      )\n",
    "\n",
    "claude_response2 = claude.invoke(messages)\n",
    "print(claude_response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3fa1ea-778b-4e9d-b992-cb6eb344ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Claudes first response with web search is crazy garbage. Can this be fixed some other way than a second call?\n",
    "print(claude_response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576f2fe-b2f1-405c-a2c6-987d2674e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4. ANTHROPIC WEBSEARCH WITH JSON SCHEMA\n",
    "# Structured Responses will not work with websearch so you have to request a JSON response which unknown accuracy??\n",
    "# alternative is Langgraph/langchain AI workflow and break it into multiple calls.\n",
    "\n",
    "\n",
    "claude = ChatAnthropic(model=\"claude-sonnet-4-20250514\", #\"claude-3-7-sonnet-20250219\",  # or \"claude-opus-4-1-20250805\", etc.\n",
    "                       temperature=0,\n",
    "                       # Pass the server tool directly; no client implementation needed\n",
    "                       max_tokens=1024,\n",
    "                       model_kwargs={\n",
    "                           \"tools\": [{\n",
    "                               \"type\": \"web_search_20250305\",\n",
    "                               \"name\": \"web_search\",\n",
    "                               \"max_uses\": 3,\n",
    "                               }]\n",
    "                           },\n",
    "                       )\n",
    "\n",
    "\n",
    "system_message = f\" You are a news summarizer. \"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=\"Summarize the most recent article you can find on OpenAI news.\")\n",
    "]\n",
    "\n",
    "claude_response1 = claude.invoke(messages)\n",
    "\n",
    "\n",
    "#Claude seems not to integrate across search results so the first call needs to be content for a second?\n",
    "schema = \"\"\"\n",
    "{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"summary\": { \"type\": \"string\" },\n",
    "    \"sources\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } }\n",
    "  },\n",
    "  \"required\": [\"summary\", \"sources\"],\n",
    "  \"additionalProperties\": false\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages.append(claude_response1)\n",
    "\n",
    "messages.append(HumanMessage(content=f\"Summarize the most recent article on OpenAI news that was returned from your previous web search. \\\n",
    "                            Return a JSON object that strictly follows this JSON schema: {schema}\"))\n",
    "claude = ChatAnthropic(model=\"claude-sonnet-4-20250514\", #\"claude-3-7-sonnet-20250219\",  # or \"\"claude-opus-4-1-20250805\", etc.\n",
    "                       temperature=0, #needs to be 0\n",
    "                       max_tokens=1024\n",
    "                      )\n",
    "\n",
    "claude_response2 = claude.invoke(messages)\n",
    "print(claude_response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa744c-073e-48ea-a4bd-1b3372512801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_JSON_FENCE_RE = re.compile(\n",
    "    r\"```(?:json)?\\s*([\\s\\S]*?)\\s*```\", re.IGNORECASE\n",
    ")\n",
    "\n",
    "def _extract_fenced_json(text: str) -> List[Dict[str, Any]]:\n",
    "    blocks = []\n",
    "    for m in _JSON_FENCE_RE.finditer(text):\n",
    "        payload = m.group(1).strip()\n",
    "        try:\n",
    "            blocks.append(json.loads(payload))\n",
    "        except json.JSONDecodeError:\n",
    "            # very last-resort: try single->double quotes if it looks like JSON-ish\n",
    "            try:\n",
    "                blocks.append(json.loads(payload.replace(\"'\", '\"')))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return blocks\n",
    "\n",
    "def _extract_inline_json(text: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Lightweight balanced-brace extractor: scans text, captures { ... } spans,\n",
    "    and attempts json.loads on each. This is conservative (skips when invalid).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    stack = []\n",
    "    start_idx = None\n",
    "    for i, ch in enumerate(text):\n",
    "        if ch == '{':\n",
    "            if not stack:  # starting a new candidate\n",
    "                start_idx = i\n",
    "            stack.append('{')\n",
    "        elif ch == '}':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "                if not stack and start_idx is not None:\n",
    "                    candidate = text[start_idx:i+1]\n",
    "                    # ignore obvious markdown artifacts\n",
    "                    if \"```\" in candidate:\n",
    "                        continue\n",
    "                    try:\n",
    "                        out.append(json.loads(candidate))\n",
    "                    except json.JSONDecodeError:\n",
    "                        # last-resort fix for single quotes\n",
    "                        try:\n",
    "                            out.append(json.loads(candidate.replace(\"'\", '\"')))\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    start_idx = None\n",
    "    return out\n",
    "\n",
    "def _gather_text_parts(content: Union[str, List[Dict[str, Any]]]) -> str:\n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "    # content is a list of parts: [{'type': 'text', 'text': '...'}, ...]\n",
    "    parts = []\n",
    "    for p in content:\n",
    "        if isinstance(p, dict) and p.get(\"type\") == \"text\":\n",
    "            parts.append(p.get(\"text\", \"\"))\n",
    "    return \"\\n\".join(parts).strip()\n",
    "\n",
    "def parse_ai_message_to_json_blocks(msg: AIMessage) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns a dict:\n",
    "      {\n",
    "        \"json_blocks\": [ {...}, {...} ],\n",
    "        \"citations\": [ {\"title\":..., \"url\":...}, ... ],\n",
    "        \"tool_outputs\": [ {...}, ... ],\n",
    "        \"raw_text\": \"<combined text content>\"\n",
    "      }\n",
    "\n",
    "    example code:\n",
    "        oai_res = oai.invoke(messages)\n",
    "        parsed = parse_ai_message_to_json_blocks(oai_res)  # result is your AIMessage\n",
    "        print(\"Found JSON blocks:\", len(parsed[\"json_blocks\"]))\n",
    "        for i, block in enumerate(parsed[\"json_blocks\"], 1):\n",
    "            print(f\"\\n# Block {i}\\n\", json.dumps(block, indent=2))\n",
    "        \n",
    "        print(\"\\nCitations:\", parsed[\"citations\"])\n",
    "        print(\"\\nTool outputs:\", parsed[\"tool_outputs\"])\n",
    "    \"\"\"\n",
    "    raw_text = _gather_text_parts(msg.content)\n",
    "\n",
    "    # 1) fenced JSON blocks\n",
    "    json_blocks = _extract_fenced_json(raw_text)\n",
    "\n",
    "    # 2) inline JSON (only if we didn't get any fenced, or to collect more)\n",
    "    inline_blocks = _extract_inline_json(raw_text)\n",
    "    # Avoid duplicates by stringifying\n",
    "    seen = {json.dumps(b, sort_keys=True) for b in json_blocks}\n",
    "    for b in inline_blocks:\n",
    "        s = json.dumps(b, sort_keys=True)\n",
    "        if s not in seen:\n",
    "            json_blocks.append(b)\n",
    "            seen.add(s)\n",
    "\n",
    "    # 3) citations from annotations (if present in parts)\n",
    "    citations: List[Dict[str, str]] = []\n",
    "    if isinstance(msg.content, list):\n",
    "        for p in msg.content:\n",
    "            for ann in p.get(\"annotations\", []) if isinstance(p, dict) else []:\n",
    "                if ann.get(\"type\") == \"url_citation\":\n",
    "                    citations.append({\n",
    "                        \"title\": ann.get(\"title\", \"\"),\n",
    "                        \"url\": ann.get(\"url\", \"\")\n",
    "                    })\n",
    "\n",
    "    # 4) tool outputs from additional_kwargs\n",
    "    tool_outputs = []\n",
    "    ak = getattr(msg, \"additional_kwargs\", {}) or {}\n",
    "    for t in ak.get(\"tool_outputs\", []) or []:\n",
    "        tool_outputs.append(t)\n",
    "\n",
    "    return {\n",
    "        \"json_blocks\": json_blocks,\n",
    "        \"citations\": citations,\n",
    "        \"tool_outputs\": tool_outputs,\n",
    "        \"raw_text\": raw_text,\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c33133-0f82-4b95-9641-cd679126e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls(text: str) -> List[str]:\n",
    "    # quick URL scrape for both vendorsâ€™ text\n",
    "    return re.findall(r'https?://\\S+', text)\n",
    "\n",
    "def extract_text_from_ai_message(msg: AIMessage) -> str:\n",
    "    \"\"\"\n",
    "     Handles OpenAI (string) and Anthropic (list of content blocks)\n",
    "    example code:\n",
    "        msg = AIMessage = claude.invoke(messages)\n",
    "        text = extract_text_from_ai_message(msg)\n",
    "    \"\"\"\n",
    "    if isinstance(msg.content, str):\n",
    "        return msg.content\n",
    "    parts = []\n",
    "    for p in msg.content:\n",
    "        if isinstance(p, dict) and p.get(\"type\") == \"text\":\n",
    "            parts.append(p.get(\"text\", \"\"))\n",
    "    return \"\\n\".join(parts).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa6f01-1e1f-476d-95f9-29b84fe7eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = ChatAnthropic(\n",
    "    model=\"claude-3-7-sonnet-20250219\",  # or \"claude-sonnet-4-20250514\", \"claude-opus-4-1-20250805\", etc.\n",
    "    temperature=0,\n",
    "    # Pass the server tool directly; no client implementation needed\n",
    "    model_kwargs={\n",
    "        \"tools\": [{\n",
    "            \"type\": \"web_search_20250305\",\n",
    "            \"name\": \"web_search\",\n",
    "            \"max_uses\": 3,\n",
    "        }]\n",
    "    },\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"Return ONLY JSON: { answer: string, sources: string[] }\"),\n",
    "    HumanMessage(content=\"What is the most recent major AI policy update? Include links.\"),\n",
    "]\n",
    "msg = AIMessage = claude.invoke(messages)\n",
    "text = extract_text_from_ai_message(msg)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce20b6a-d6ae-4900-a470-ea7fac10d040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
